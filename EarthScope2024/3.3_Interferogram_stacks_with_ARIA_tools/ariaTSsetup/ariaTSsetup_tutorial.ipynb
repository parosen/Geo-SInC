{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing ARIA standard GUNW products layers for time-series analysis using ariaTSsetup.py\n",
    "\n",
    "**Author**: Simran Sangha, David Bekaert - Jet Propulsion Laboratory\n",
    "\n",
    "This notebook provides an overview of the functionality included in the **ariaTSsetup.py** program. Specifically, we give examples on how to extract data and meta-data layers from ARIA Geocoded UNWrapped interferogram (GUNW) products over a user defined area of interest and prepare the data into a stack for time-series ingestion.\n",
    "\n",
    "In this notebook, we will demonstrate how to:\n",
    "- Extract data layers (unwrapped phase, coherence) and imaging geometry layers (azimuth angle, incidence angle, look angle) necessary for building time-series\n",
    "- Prepare the extracted data into a stack for time-series ingestion\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "Both the initial setup (<b>Prep A</b> section) and download of the data (<b>Prep B</b> section) should be run at the start of the notebook. The overview sections do not need to be run in order. In the application section the ariaTSsetup commandline call at the top must be run first, but the rest of the section does not need to be run in order.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Potential Errors:</b> \n",
    "    \n",
    "- GDAL uses \"HDF5\" driver instead of \"netCDF/Network Common Data Format\" on GUNW products. Verify GDAL version >= 3.\n",
    "- ARIA-tools needs to be installed to run this notebook\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Terminology:</b>\n",
    "    \n",
    "- *Acquisition*: An image acquired by the satellite for a given date and time.\n",
    "- *Interferogram*: An unwrapped image containing the surface displacement accumulated between two acquisitions.\n",
    "- *Frame*: Outline of a product ground footprint.\n",
    "- *Along-track*: The direction along satellite flight path. \n",
    "    </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep A. Initial setup of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we set up the directory structure for this notebook exercise. In addition, we load the required modules into our python environment using the **`import`** command. We also explicitly enable exceptions for GDAL as this allows us to capture GDAL errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to control the use of pre-staged data; [False/True]\n",
    "Use_Staged_Data = True\n",
    "\n",
    "# ------------------------------------------------------------------------------------------- #\n",
    "# no changed below needed:\n",
    "\n",
    "import os, copy\n",
    "import shutil\n",
    "import subprocess\n",
    "from osgeo import gdal, ogr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, FormatStrFormatter, StrMethodFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import copy\n",
    "    \n",
    "\n",
    "## Defining the home and data directories at the processing location\n",
    "work_dir = os.path.abspath(os.getcwd())\n",
    "tutorial_home_dir = os.path.abspath(os.getcwd())\n",
    "print(\"Work directory: \", work_dir)\n",
    "print(\"Tutorial directory: \", tutorial_home_dir)\n",
    "\n",
    "# Enable GDAL/OGR exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# Verifying if ARIA-tools is installed correctly\n",
    "try:\n",
    "    import ARIAtools.util.shp as shputil\n",
    "except:\n",
    "    raise Exception('ARIA-tools is missing from your PYTHONPATH')\n",
    "        \n",
    "os.chdir(work_dir)\n",
    "\n",
    "if Use_Staged_Data:\n",
    "    # Check if a stage file from S3 already exist, if not try and download it\n",
    "    f = 'ariaTSsetup.zip'\n",
    "    if not os.path.isfile(f):\n",
    "        print('\\nAttempting to download staged data ... ')\n",
    "        try:\n",
    "            cmd = 'aws s3 cp --region us-east-1 --no-sign-request ' + \\\n",
    "                  f's3://asf-jupyter-data-west/aria-data/{f} {f}'\n",
    "            subprocess.run(cmd, shell=True, check=True)\n",
    "                \n",
    "        except:\n",
    "            cmd = 'wget --no-check-certificate --no-proxy ' + \\\n",
    "                  'http://asf-jupyter-data-west.s3.amazonaws.com/' + \\\n",
    "                  f'aria-data/{f} {f} -q --show-progress'\n",
    "            subprocess.run(cmd, stdout=None, stderr=subprocess.PIPE, shell=True)\n",
    "\n",
    "    # verify if download was successful\n",
    "    if os.path.isfile(f):\n",
    "        if os.path.exists('products'):\n",
    "            shutil.rmtree('products')\n",
    "        !unzip {f}\n",
    "        print('S3 pre-staged data retrieval was successful')\n",
    "    else:\n",
    "        print('Download outside openSarLabs is not supported.\\n '\n",
    "              'As alternative please start from ARIA-tools with the '\n",
    "              'commandline calls provided at the top of this notebook')\n",
    "else:\n",
    "    print(\"Will not be using S3 pre-staged data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEMs are accessed/downloaded through OpenTopography. Downloading them requires an OpenTopography api key.\n",
    "\n",
    "Follow instructions listed here to generate and access API key through OpenTopography:\n",
    "https://opentopography.org/blog/introducing-api-keys-access-opentopography-global-datasets\n",
    "\n",
    "Once the api key is acquired, your local **`.topoapi`** may be populated by executing the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create .topoapi if it does not exist    \n",
    "if not os.path.exists(os.path.expanduser('~/.topoapi')):\n",
    "    print('API key location: My Account > myOpenTopo Authorizations ' + \\\n",
    "          'and API Key > Request API key')\n",
    "    opentopography_api_key = input('Please type your OpenTopo API key:')\n",
    "    opentopography_api_key = str(opentopography_api_key)\n",
    "    os.system('echo \"{api_key}\" > ~/.topoapi; chmod 600 ~/.topoapi'.format(\n",
    "        api_key = str(opentopography_api_key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a plotting function that will be used throughout the notebook for plotting GDAL compatible datasets on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_layer(path_layer, lay_type=None, cmap=None, n_bands=None, **kwargs):\n",
    "    \"\"\" \n",
    "        path_layer is a string to the GDAL compatible dataset to be plotted\n",
    "    \"\"\"\n",
    "  \n",
    "    if not lay_type: \n",
    "        lay_type = os.path.dirname(path_layer)\n",
    "    title = [os.path.basename(lay_type)]\n",
    "    \n",
    "    ## get the lon lat bounds\n",
    "    ds       = gdal.Open(path_layer, gdal.GA_ReadOnly)\n",
    "    trans    = ds.GetGeoTransform()\n",
    "    extent   = [trans[0], trans[0] + ds.RasterXSize * trans[1],\n",
    "                trans[3] + ds.RasterYSize*trans[5], trans[3]]\n",
    "    \n",
    "    ## loading the data\n",
    "    if not n_bands:\n",
    "        n_bands  = ds.RasterCount\n",
    "    lst_arrs = []\n",
    "    \n",
    "    for band in range(n_bands):\n",
    "        raster = ds.GetRasterBand(band+1)\n",
    "        arr    = raster.ReadAsArray()\n",
    "        try:\n",
    "            NoData = raster.GetNoDataValue()\n",
    "            arr = np.ma.masked_where((arr>1e20) |(arr==NoData),arr )\n",
    "        except:\n",
    "            print('Could not find a no-data value...')\n",
    "            arr = np.ma.masked_where(arr>1e20,arr)\n",
    "        \n",
    "        lst_arrs.append(arr)\n",
    "\n",
    "    ds = None\n",
    "    if n_bands < 4:\n",
    "        nrows = 1; ncols = n_bands\n",
    "    else:\n",
    "        raise Exception('Number of bands currently unsupported')\n",
    "        \n",
    "    \n",
    "    ## initializing a figure\n",
    "    fig, axes = plt.subplots(figsize=(12,9), ncols=ncols, nrows=nrows,\n",
    "                             sharex='col', sharey='row')\n",
    "    axes = axes if isinstance(axes, np.ndarray) else np.array(axes)\n",
    "    axe  = axes.ravel() \n",
    "    cmap = copy.copy(plt.cm.Greys_r)\n",
    "    cmap.set_under('black')\n",
    "    vmin = None\n",
    "    vmax = None\n",
    "    \n",
    "    ## defining the plotting options for different layer types\n",
    "    # Amplitude:\n",
    "    if lay_type.endswith('amplitude'): \n",
    "        # will fix the maximum amplitude bound\n",
    "        vmax = 2000 \n",
    "   \n",
    "    # Coherence:\n",
    "    elif lay_type.endswith('coherence'): \n",
    "        # has fixed range between 0-1\n",
    "        vmin, vmax = 0, 1\n",
    "\n",
    "    # water\n",
    "    elif lay_type.startswith('water'):\n",
    "        # no bounds needed will be a 0/1 mask\n",
    "        # match mintpy\n",
    "        arr = np.ma.getdata(lst_arrs[0])\n",
    "        lst_arrs[0] = arr\n",
    "        vmin=0\n",
    "        vmax=1\n",
    "        cmap='binary_r'\n",
    "\n",
    "    # deformation or unwrapped phase\n",
    "    elif lay_type.startswith('defo'): \n",
    "        cmap = plt.cm.coolwarm\n",
    "   \n",
    "    elif lay_type.startswith('terr') or lay_type.startswith('topo'): \n",
    "        cmap = plt.cm.terrain\n",
    "    \n",
    "    elif lay_type == 'ENU':\n",
    "        title = ['East', 'North', 'Up']\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "\n",
    "    else:\n",
    "        # change colormap to a warm type\n",
    "        cmap = plt.cm.coolwarm\n",
    "        \n",
    "    # plotting the data    \n",
    "    for i, ax in enumerate(axe):\n",
    "        im   = ax.imshow(lst_arrs[i], cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "                         extent=extent,interpolation='nearest')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax     = divider.append_axes('right', size='5%', pad=0.25)\n",
    "        if lay_type == 'ENU':\n",
    "            fig.colorbar(im, cax=cax,\n",
    "                         format=FuncFormatter(lambda x, y: '{:.3f}'.format(x)))\n",
    "        elif lay_type.startswith('water'):\n",
    "            fig.colorbar(im, cax=cax, ticks=[vmin, vmax])\n",
    "        else:\n",
    "            fig.colorbar(im, cax=cax)\n",
    "\n",
    "        ax.set_title(title[i], fontsize=15)\n",
    "        ax.grid(False)\n",
    "\n",
    "    axe[0].set_ylabel('latitude', labelpad=15, fontsize=15)\n",
    "    axe[int(np.floor(n_bands/2))].set_xlabel('longitude', labelpad=15, fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep B: Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use San Francisco as the study area for this tutorial (see **Fig. 1**). Specifically, we will use Sentinel-1 interferograms generated on track 35, spanning the start of the Sentinel-1 mission phase in late 2014 up until the present day.\n",
    "\n",
    "ARIA provides unwrapped interferograms as GUNW products. As the spatial extent of a product is roughly the size of a single Sentinel-1 SLC frame (250km x 250km), it is likely that a given interferogram over this study area is composed of multiple adjacent GUNW frames or products.\n",
    "\n",
    "<img src=\"./support_docs/track_035.png\" alt=\"track\" width=\"600\">\n",
    "\n",
    "<blockquote><b>Fig. 1</b> Image of San Francisco study area centered along track 35. Blue and white boxes denote footprint of a product and the bounding box of our study area. Faults from USGS Quaternary fault catalog are plotted in background. For interpretation of fault trace colors, refer to see <a href=\"https://www.usgs.gov/natural-hazards/earthquake-hazards/faults\">USGS fault catalogue website</a>. </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIA GUNW products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GUNW product is an InSAR surface displacement product derived from Sentinel-1 SAR data and packaged as netCDF4 files. GUNW products contain both data and meta-data layers such as the interferometric amplitude, filtered unwrapped phase, filtered coherence, connected components, perpendicular and parallel baselines, incidence, azimuth and look angles. A detailed overview of the ARIA GUNW product with respect to processing, formatting, sampling, and data layers can be found on the [ARIA website](https://aria.jpl.nasa.gov/node/97)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUNW products are hosted at the ASF DAAC and can be downloaded from the [ARIA-products page](https://aria-products.jpl.nasa.gov) and as beta products from the [ASF DAAC data search page](https://search.asf.alaska.edu/#/). If you know the GUNW filename of the product, you can also build a download link by appending the GUNW filename to **https://<i></i>grfn.asf.alaska.edu<i></i>/door/download/** . \n",
    "\n",
    "Alternatively, you can use the **`ariaDownload.py`** program provided within the ARIA-tools package to download data using a command-line interface. This program wraps around the ASF DAAC API and allows for search sub-setting of GUNW products based on track number, geometry (ascending or descending), as well as spatial and temporal bounding boxes criteria. For a full description of the **`ariaDownload.py`** program, see the [ariaDownload Tutorial](https://github.com/aria-tools/ARIA-tools-docs/blob/master/JupyterDocs/ariaDownload/ariaDownload_tutorial.ipynb).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Potential download failure:</b> \n",
    "GUNW products are hosted at the NASA ASF DAAC. Downloading them requires a NASA Earthdata URS user login and requires users to add “ARIA Product Search” to their URS approved applications\n",
    "\n",
    "<b>Login Credentials:</b>\n",
    "Save your user-name and password to a `.netrc` file in your `$HOME` directory, or pass the combination explicitly using `ariaDownload.py --user <user> --pass <pass>`.\n",
    "\n",
    "\n",
    "To create a .netrc file, pass your earthdata credentials by running the cell below\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Download</b>:     \n",
    "    \n",
    "- Can take up to 40 mins, so this is a good moment to take a coffee-break! - The ***jupyter notebook* does not allow for interactive entering of your user-name and password, use the *jupyter terminal* instead** with the same command for interactive use.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create .netrc if it does not exist    \n",
    "if not os.path.exists(os.path.expanduser('~/.netrc')):\n",
    "    print('NEEDED To Download ARIA GUNWs: \\n '\n",
    "          'Link to create account : https://urs.earthdata.nasa.gov/')\n",
    "    earthdata_user = input('Please type your Earthdata username:')\n",
    "    earthdata_user = str(earthdata_user)\n",
    "    earthdata_password = input('Please type your Earthdata password:')\n",
    "    earthdata_password = str(earthdata_password)\n",
    "    os.system('echo machine urs.earthdata.nasa.gov login \"{usern}\" '\n",
    "              'password \"{passwd}\" > ~/.netrc; chmod 600 ~/.netrc'.format(\n",
    "              usern = earthdata_user, passwd = earthdata_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Use_Staged_Data:\n",
    "    # limit to 88 products\n",
    "    !ariaDownload.py --track 35 --bbox '37.25 38.1 -122.6 -121.75' \\\n",
    "                     --start 20190101 --end 20200101 --version '3_0_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now have a look at the downloaded products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product filename has two fields, **XXYYYN/S-XXYYYN/S**, that are respectively associated with the western edge of south and north most corner of the geocoded interferogram (see [aria-website](https://aria.jpl.nasa.gov/products/standard-displacement-products.html) for a complete overview of the filename convention). The latitude bounds are specified as 5-digit number with 3 significant digits. The `duplicated_products` directory contains products that are the same except for the version. The default is to keep the newest versions and store any others in `duplicated_products`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the ariaTSsetup.py program\n",
    "<a id='overview'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`ariaTSsetup.py`** program allows for easy time-series preparation of relevant data and meta-data layers from ARIA standard GUNW products. The **`ariaTSsetup.py`** program is functionally very similar to the **`ariaExtract.py`** program, aside from the aforementioned note that the former prepares extracted data into a stack for time-series ingestion. The program will automatically determine which GUNW products need to be stitched or cropped in order to generate a seamless interferogram. By default, interferograms will be cropped to bounds determined by the common intersection and bounding box (if specified). Running **`ariaTSsetup.py`** with the **`-h`** option will show the parameter options. \n",
    "\n",
    "Let us explore these options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ariaTSsetup.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Product files to be used (-f option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At minimum, users need to specify the GUNW files they want to extract information from. This is controlled using the **`-f`** option. Multiple products can be specified by providing them as a comma separated string (e.g., **`-f`**` 'products/S1-GUNW-D-R-042-tops-20150605_20150512-140722-39616N_37642N-PP-e396-v2_0_0.nc,products/S1-GUNW-D-R-042-tops-20150629_20150512-140723-39615N_37641N-PP-0e95-v2_0_0.nc'`), or using a wildcard (e.g., **`-f`**` 'products/S1*.nc'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Layers to be extracted (-l option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the following are extracted: bounding boxes of the products, the \"unwrappedPhase\", \"coherence\", \"incidenceAngle\", \"lookAngle\", and \"azimuthAngle\" layers necessary for building time-series. Layer extraction is controlled using the **`-l`** option. Additional valid options are \"amplitude\", \"bPerpendicular\", and \"bParallel\". Multiple layers can be extracted at once by specifying them as a comma separated string (e.g., **`-l`**` 'azimuth,bParallel'`). You can use the `'all'` keyword to extract all possible layers at once (e.g., **`-l`**` all`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DEM (-d and -p options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By specifying the **`-d`**` Download` option, users can download the Copernicus GLO-90 DEM on the fly. The DEM will be cropped over the interferogram extent (ground swath). A DEM is required for extracting the meta-data layer fields (e.g., \"bPerpendicular\", \"bParallel\", \"incidenceAngle\",\"lookAngle\", and \"azimuthAngle\"). Alternatively, users can also specify the location to a custom GDAL-compatible DEM and control its projection by specifying it with the **`-p`** option. All the meta-data layers are stored within the GUNW product as 3D data cubes (longitude, latitude, height). The full-resolution meta-data layers are generated by intersecting these 3D data-cube with the DEM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mask (-m option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By specifying the **`-m`**` Download` option, users can download a waterbody mask compiled from the Global Self-consistent, Hierarchical, High-resolution Geography Database (GSHHG) on the fly. The mask will be cropped over the interferogram extent (ground swath). A mask is useful for masking out broader waterbodies (e.g. oceans and major lakes) from your output layers. Alternatively, users can also specify the location to a custom GDAL-compatible mask and control its projection by specifying it with the **`-p`** option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cropping and spatial sub setting (--bbox and -croptounion options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`ariaTSsetup.py`** program will automatically handle cropping and stitching of GUNW products when needed. By default, the program will crop all interferograms to bounds determined by the common intersection (of all interferograms) and the user-defined bounding box (**`-bbox`** SNWE option). All layers are cropped and/or stitched using GDAL (see the methods section for details on the implemented approach for each layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Workdirectory (-w option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the **`ariaTSsetup.py`** program is saved within the working directory (**`-w`**), which by default is the current directory. Within the work directory the outputs are organized in separate subdirectories, where the sub-directory name corresponds to the layer being extracted. Within each subdirectory, the data and meta-data are saved with the interferogram pair dates \"date1_date2\" serving as the basename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Output format (-o option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`ariaTSsetup.py`** program leverages GDAL for file reading and writing of outputs. The user can therefore specify any GDAL compatible format (e.g., ENVI, ISCE, GTiff; see GDAL for more information on supported formats) for saving the outputs from **`ariaTSsetup.py`**.  By default, \"unwrappedPhase\", \"bPerpendicular\", \"bParallel\", \"incidenceAngle\", \"lookAngle\", and \"azimuthAngle\" are stored as ENVI files, as these layers required  mathematical manipulation. Other layers including \"coherence\" and \"amplitude\" do not require this, and by default are stored as virtual files (.vrt) to conserve disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **`ariaTSsetup.py`** to build a stack of products for time-series ingestion. We will use the GUNW products you have already downloaded into a *products* subfolder within in your specified *work directory* (**`-w`** option), which were collected on track *42* over the San Francisco area *'37.25 38.1 -122.6 -121.75'* (**`-bbox`** SNWE option) and spanning from late 2014 through to the present day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of ariaTSprep.py program "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up time-series stack, download DEM and mask using ariaTSsetup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ariaTSsetup.py -f 'products/*.nc' -b '37.25 38.1 -122.6 -121.75' \\\n",
    "                -mo 5520 -d Download --mask Download -nt 10 \\\n",
    "                -l 'solidEarthTide,troposphereTotal,ionosphere' -tm HRRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and crop layers to the box defined for the San Francisco area *'37.25 38.1 -122.6 -121.75'* (**`-bbox`** SNWE option), download a DEM (**`-d Download`** option) which is needed to extract meta-data layers prerequisite for time-series analysis, and download a mask (**`-m Download`** option) to remove waterbodies.\n",
    "\n",
    "We specify a minimum overlap (**`-mo`**` minimumOverlap` option) of 5520 km<sup>2</sup> in order to reject shorter scenes which do not maintain sufficient coverage with respect to the defined region of interest. If we do not do this, then the common intersection of all scenes will have a limited footprint. See the ariaExtract_tutorial.ipynb for a more detailed overview of the Minimum Overlap option.\n",
    "\n",
    "The default data layers (unwrapped phase, coherence) and imaging geometry layers (azimuth angle, incidence angle, look angle) necessary for building time-series have been extracted. Layers are extracted to separate subdirectories named after the 'layer name' under the specified working directory (`-w`), e.g. 'unwrappedPhase'. Within the layer subdirectories, the data and meta-data are saved with a given interferometric date combination serving as the filename, e.g. 'unwrappedPhase/20150605_20150512'. Any existing layers will be overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View downloaded mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download a waterbody mask compiled from GSHHG, we specified the **`-m Download`** option. By default, outputs are written to the local directory, which can be changed to another location by specifying the path with the **`-w`** option. The mask will be applied to all extracted layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask is cropped to the common interferometric grid, stored under local subdirectory *mask*, and given the filename *watermask.msk* (i.e. nested as *mask/watermask.msk*). Note that for consistency, if a user specifies a path to a custom mask, the cropped version is still stored under the local subdirectory *mask* and shares the same filename as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to visualize the mask. Broader waterbodies (e.g. oceans and major lakes) are delineated in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layer('mask/esa_world_cover_2021.msk',lay_type='water')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will apply this mask to the unwrapped phase layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## view the plot\n",
    "plot_layer('unwrappedPhase/20190121_20190109', 'deformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View downloaded DEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download a Copernicus GLO-90, we specified the **`-d Download`** option. By default, outputs are written to the local directory, which can be changed to another location by specifying the path with the **`-w`** option. A DEM is needed for the extraction of full resolution meta-data layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DEM is cropped to the common interferometric grid, stored under local subdirectory *DEM*, and given the filename *glo_90.dem* (i.e. nested as *DEM/glo_90.dem*). Note that for consistency, if a user specifies a path to a custom DEM, the cropped version is still stored under the local subdirectory *DEM* and shares the same filename as the input. You can use gdalinfo to retrieve information on the geospatial extent of the DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls DEM/glo_90*\n",
    "!gdalinfo DEM/glo_90.dem.vrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to visualize the DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layer('DEM/glo_90.dem',lay_type='topo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine *stack* files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three VRT files *cohStack.vrt*, *connCompStack.vrt*, *unwrapStack.vrt* have been generated under the *stack* subdirectory of your specified work directory. They point to your extracted coherence, connected component, and unwrapped phase files, respectively. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the  **gdalinfo** to retrieve an overview of *unwrapStack.vrt*. You will see that it contains paths pointing each of the extracted interferograms in your stack, and basic projection information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalinfo stack/unwrapStack.vrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **`-mdd unwrappedPhase`** option in **gdalinfo** to access the radar metadata (e.g. orbitDirection, UTCTime, Wavelength) corresponding to each of the interferogram data-layers, which are stored under the key-name *unwrappedPhase*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalinfo stack/unwrapStack.vrt -mdd unwrappedPhase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our earlier defined plotting function to visualize one of the interferograms in your stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layer('stack/unwrapStack.vrt', 'deformation', n_bands=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If correction layers are available and extracted, they will also appear as VRT files in the *stack* subdirectory, i.e., *troposphereTotal/HRRRStack.vrt*, *setStack.vrt*, and *ionoStack.vrt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the troposphere layers are located in a subdirectory according to the component that is extracted (i.e., hydrostatic and wet, or total troposphere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls stack/troposphereTotal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
