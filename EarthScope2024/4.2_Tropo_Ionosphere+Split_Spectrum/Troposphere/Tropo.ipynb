{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tropospheric corrections using GACOS\n",
    "**Author**: Bekaert David, Simran Sangha - Jet Propulsion Laboratory\n",
    "\n",
    "In this notebook, we will walk through the steps in order to correct a geo-coded interferogram with GACOS. \n",
    "We will apply the corrections to a topsApp geo-coded Sentinel-1 interferogram of the 12 November 2017 Mw7.3 earthquake that occurred in Iran.\n",
    "\n",
    "![title](support_docs/region.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0. Initial set-up for the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will start with the initial set-up of the notebook. This step only needs to be run at the very beginning and defines the processing locations as well as a few plotting routines that will be used throughout the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'isce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cl/wvprkp1s4p34cjvnt87q2vf1kglfv2/T/ipykernel_36610/796746177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m                \u001b[0;31m## Matrix calculations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m                       \u001b[0;31m## Retrieving list of files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0misce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m## Defining the home directory as an absolute path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'isce'"
     ]
    }
   ],
   "source": [
    "# option to control the use of pre-staged data; [False/True]\n",
    "Use_Staged_Data = True\n",
    "\n",
    "# ------------------------------------------------------------------------------------------- #\n",
    "# no changes below needed:\n",
    "\n",
    "from shutil import copyfile\n",
    "from osgeo import gdal            ## GDAL support for reading virtual files\n",
    "import os                         ## To create and remove directories\n",
    "import matplotlib.pyplot as plt   ## For plotting\n",
    "import numpy as np                ## Matrix calculations\n",
    "import glob                       ## Retrieving list of files\n",
    "import isce \n",
    "\n",
    "## Defining the home directory as an absolute path\n",
    "if 'tutorial_home_dir' in locals(): \n",
    "    print(tutorial_home_dir)\n",
    "    pass\n",
    "else:\n",
    "    # define local paths\n",
    "    tutorial_home_dir = os.getcwd()\n",
    "print(tutorial_home_dir) \n",
    "## If specified, prep and use staged data\n",
    "if Use_Staged_Data:\n",
    "    # Check if a stage file from S3 already exist, if not try and download it\n",
    "    if not os.path.isfile('tropo.zip'):\n",
    "        !aws s3 cp --region us-east-1 --no-sign-request s3://asf-jupyter-data/unavco2021/tropo.zip tropo.zip\n",
    "\n",
    "    # verify if download was succesful\n",
    "    if os.path.isfile('tropo.zip'):\n",
    "        if os.path.isdir('tropoStageData'):\n",
    "            !rm -rf tropoStageData\n",
    "        !unzip tropo.zip\n",
    "        print('S3 pre-staged data retrieval was successful')\n",
    "    else:\n",
    "        print(\"Download outside openSarLabs is not supported.\")\n",
    "    # define local paths\n",
    "else:\n",
    "    print(\"Will not be using S3 pre-staged data\")\n",
    "\n",
    "\n",
    "print(\"home directory: \", tutorial_home_dir)\n",
    "processing_dir = os.path.join(tutorial_home_dir,'insar','merged')\n",
    "processing_slc_dir = os.path.join(tutorial_home_dir,'slc')\n",
    "if not os.path.isdir(tutorial_home_dir):\n",
    "    os.makedirs(tutorial_home_dir)\n",
    "if not os.path.isdir(processing_slc_dir):\n",
    "    os.makedirs(processing_slc_dir)\n",
    "os.chdir(tutorial_home_dir)\n",
    "\n",
    "# define gacos path\n",
    "gacos_dir  =  os.path.join(tutorial_home_dir,'gacos_download')\n",
    "# generate all the folders in case they do not exist yet\n",
    "if not os.path.isdir(gacos_dir):\n",
    "    os.makedirs(gacos_dir)\n",
    "if not os.path.isdir(processing_dir):\n",
    "    os.makedirs(processing_dir)\n",
    "    \n",
    "# defining backup dirs in case of download issues on the local server\n",
    "data_backup_dir = os.path.abspath(os.path.join(tutorial_home_dir,\"tropoStageData\"))\n",
    "gacos_backup_dir = os.path.join(data_backup_dir,'gacos_backup')\n",
    "processing_backup_dir  =  os.path.join(data_backup_dir,'insar','merged')\n",
    "processing_slc_backup_dir  =  os.path.join(data_backup_dir,'slc')\n",
    "    \n",
    "# copy in the InSAR data \n",
    "cmd = \"cp -r \" + os.path.join(processing_backup_dir,'*') + \" \" + os.path.join(processing_dir,'.')\n",
    "os.system(cmd)\n",
    "cmd = \"cp -r \" + os.path.join(processing_slc_backup_dir,'*') + \" \" + os.path.join(processing_slc_dir,'.')\n",
    "os.system(cmd)\n",
    "\n",
    "\n",
    "\n",
    "def plotdata(GDALfilename,band=1,title=None,colormap='gray',aspect=1, datamin=None, datamax=None,draw_colorbar=True,colorbar_orientation=\"horizontal\",background=None):\n",
    "    ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "    data = ds.GetRasterBand(band).ReadAsArray()\n",
    "    transform = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    \n",
    "    # getting the min max of the axes\n",
    "    firstx = transform[0]\n",
    "    firsty = transform[3]\n",
    "    deltay = transform[5]\n",
    "    deltax = transform[1]\n",
    "    lastx = firstx+data.shape[1]*deltax\n",
    "    lasty = firsty+data.shape[0]*deltay\n",
    "    ymin = np.min([lasty,firsty])\n",
    "    ymax = np.max([lasty,firsty])\n",
    "    xmin = np.min([lastx,firstx])\n",
    "    xmax = np.max([lastx,firstx])\n",
    "\n",
    "    # put all zero values to nan and do not plot nan\n",
    "    if background is None:\n",
    "        try:\n",
    "            data[data==0]=np.nan\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.imshow(data, vmin = datamin, vmax=datamax, cmap=colormap,extent=[xmin,xmax,ymin,ymax])\n",
    "    ax.set_title(title)\n",
    "    if draw_colorbar is not None:\n",
    "        cbar = fig.colorbar(cax,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)    \n",
    "    plt.show()\n",
    "    data = None\n",
    "\n",
    "def plotdata2(GDALfilename1,GDALfilename2,band=1,title=None,colormap='gray',aspect=1, datamin=None, datamax=None,draw_colorbar=True,background=None,plot_profile=None):\n",
    "   \n",
    "    # profiles to be drawn if requested\n",
    "    profiles_x = [1100,600]\n",
    "    profiles_y = [1600,600]\n",
    "\n",
    "\n",
    "    # plotting a two pannel dataset\n",
    "    counter=1\n",
    "    GDALfilenames = [GDALfilename1,GDALfilename2]\n",
    "    fig = plt.figure(figsize=(9, 8))\n",
    "    for GDALfilename in GDALfilenames:\n",
    "        ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "        data = ds.GetRasterBand(band).ReadAsArray()\n",
    "        transform = ds.GetGeoTransform()\n",
    "        ds = None\n",
    "\n",
    "        # getting the min max of the axes\n",
    "        firstx = transform[0]\n",
    "        firsty = transform[3]\n",
    "        deltay = transform[5]\n",
    "        deltax = transform[1]\n",
    "        lastx = firstx+data.shape[1]*deltax\n",
    "        lasty = firsty+data.shape[0]*deltay\n",
    "        ymin = np.min([lasty,firsty])\n",
    "        ymax = np.max([lasty,firsty])\n",
    "        xmin = np.min([lastx,firstx])\n",
    "        xmax = np.max([lastx,firstx])\n",
    "\n",
    "        ax = fig.add_subplot(1,2,counter)\n",
    "        \n",
    "        # put all zero values to nan and do not plot nan\n",
    "        if background is None:\n",
    "            try:\n",
    "                data[data==0]=np.nan\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cax = ax.imshow(data, vmin = datamin, vmax=datamax, cmap=colormap,extent=[xmin,xmax,ymin,ymax])\n",
    "         \n",
    "\n",
    "        # in case a profile is requested to be plotted, then show it on the overview figure and compute the profile\n",
    "        if plot_profile is not None:\n",
    "            if counter==1:\n",
    "                data1=[]\n",
    "                linetype='-'\n",
    "                linecolor='magenta'\n",
    "                for profile_x in profiles_x:\n",
    "                    data1.append(data[0:-1,profile_x])  \n",
    "                for profile_y in profiles_y:\n",
    "                    data1.append(data[profile_y,0:-1])\n",
    "            elif counter==2:\n",
    "                data2=[]\n",
    "                linetype='--'\n",
    "                linecolor='k'\n",
    "                for profile_x in profiles_x:\n",
    "                    data2.append(data[0:-1,profile_x])  \n",
    "                for profile_y in profiles_y:\n",
    "                    data2.append(data[profile_y,0:-1])\n",
    "\n",
    "            # plot the profiles on the figure\n",
    "            count_profile_total=0\n",
    "            for profile_y in profiles_y:\n",
    "                profile_lat = firsty+profile_y*deltay\n",
    "                ax.plot([xmin, xmax],[profile_lat, profile_lat],linestyle=linetype, color=linecolor)\n",
    "                count_profile_total +=1\n",
    "                ax.text(np.mean([xmin,xmax]),profile_lat,str(count_profile_total),fontsize=20)\n",
    "            for profile_x in profiles_x:\n",
    "                profile_lon = firstx+profile_x*deltax\n",
    "                ax.plot([profile_lon, profile_lon],[ymin,ymax],linestyle=linetype, color=linecolor)\n",
    "                count_profile_total +=1\n",
    "                ax.text(profile_lon,np.mean([ymin,ymax]),str(count_profile_total),fontsize=20)\n",
    "\n",
    "        \n",
    "        ax.set_title(title[counter-1])\n",
    "        if draw_colorbar is not None:\n",
    "            cbar = fig.colorbar(cax,orientation=\"horizontal\")\n",
    "        ax.set_aspect(aspect)\n",
    "        counter +=1\n",
    "    plt.show()\n",
    "    \n",
    "    # plotting the profile if requested\n",
    "    if plot_profile is not None:\n",
    "        fig2 = plt.figure(figsize=(15, 14))\n",
    "        for i_profile in range(count_profile_total):\n",
    "            ax = fig2.add_subplot(count_profile_total,1,i_profile+1)\n",
    "            ax.plot(range(len(data2[i_profile])),data2[i_profile],'--',color='k')\n",
    "            ax.plot(range(len(data1[i_profile])),data1[i_profile],'-',color='magenta')\n",
    "            ax.set_title('profile number ' + str(i_profile+1))\n",
    "        plt.show()\n",
    "        \n",
    "    data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1. Overview of the tutorial input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following steps require geocoded interferogram products that are compatible with gdal and have correct georeference information stored in their metadata. Geocoded **ISCE** product have a **.geo** suffix, while the addition of the **.vrt** suffix makes sure the products are also compatible with gdal. \n",
    "\n",
    "As part of this tutorial we use a Sentinel-1 dataset which has already been pre-processed with *topsApp.py*. You can find the unwrapped interferogram (*filt_topophase.flat.geo*) and the line-of-sight angles (*los.rdr.geo*), containing incidence and heading, in the **insar/merged** data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: insar/merged: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls insar/merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To verify that your *FILE* is gdal compatible try to run:\n",
    "```\n",
    "    gdalinfo FILE\n",
    "```\n",
    "Verify the coordinate information to ensure the parsing from the metadata is done correctly. This can be done by investigating the output from gdalinfo: \n",
    "- Coordinate System: typically reports an EPSG code, or spells out the coodinate system in its complete such as WGS84.\n",
    "- Origin: the origin of the coordinate system\n",
    "- Pixel Size: the sampling/resolution of the data\n",
    "- Corner Coordinates: longitude and latitude corners of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 4: insar/merged/filt_topophase.unw.geo.vrt: No such file or directory\r\n",
      "gdalinfo failed - unable to open 'insar/merged/filt_topophase.unw.geo.vrt'.\r\n"
     ]
    }
   ],
   "source": [
    "!gdalinfo insar/merged/filt_topophase.unw.geo.vrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The names of the original input SLC's used in the processing are containted in the **SLC** folder. By exploring the SLC folder, you can see that these products files are zip archives. When unpacked the zip extension will be replaced by SAFE. The products are therefore also frequently called SAFE files. The SAFE filenames provide information on the product type, the polarization, the start and stop acquisition time. For example: S1A_IW_SLC__1SDV_20171111T150004_20171111T150032_019219_0208AF_EE89.zip \n",
    "- Type = slc\n",
    "- Polarization = Dual pole \n",
    "- Date = 20171111\n",
    "- UTC time of acquisition = ~15:00\n",
    "- Sensing start for the acquisition was 20171111 at 15:00:04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2. Overview of the GACOS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.1 Background on GACOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Generic Atmospheric Correction Online Service for InSAR (GACOS) allows for the on-demand generation of zenith tropospheric delay maps given a user specified region of interest, date, and UTC time. Currently no command line API exist, but orders can be submitted using the online form at: http://www.gacos.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2 GACOS download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us first find all the required information needed to complete online GACOS fields "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.2.1 Dates and UTC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Dates** and **UTC**: For sentinel-1, the date and UTC information can be directly extracted from the original SAFE filename. For example: S1A_IW_SLC__1SDV_20171111T150004_20171111T150032_019219_0208AF_EE89 corresponds to an acquisition made on 20171111 at ~15:00 UTC. \n",
    "\n",
    "What are the other dates and do they roughly have the same acquisition time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!grep slc insar/merged/topsApp.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.2.2 Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Region**: You can extract the region information directly from the .geo.vrt file with gdalinfo. Look at the corner coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!gdalinfo insar/merged/filt_topophase.unw.geo.vrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.2.3 Summary of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- dates: 20171111 and 20171117\n",
    "- UTC: ~15:00 UTC (UTC does not vary much for SAR satellites due to their typical sun synchronous dawn-dusk orbit)\n",
    "- region: North=35.49, South=33.82, West=45.25, East=46.55\n",
    "- data type: Geotiff\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE on REGION:</b> \n",
    "For ease we will select a region of integer degrees. **Region: North=36, South=33, West=45, East=47**\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>NOTE on Data type:</b>\n",
    "GACOS supports both tiff and Binary grid formats. This notebook has pre-staged backup data in Binary Grid format. If executed in tiff format the first pre-processing step should be skipped. Additionally one should add suffix .tif to filenames.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2.2.4 Placing GACOS order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we have all the required parameters at hand, initiate the GACOS request online at http://www.gacos.net/. Once you submit the order, an email will be send to the provided email adress informing you about the job submission.\n",
    "![title](support_docs/gacos_order.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A second email will be send to you once the processing has completed, depending on the number of requests this could take a few minutes or longer. The completion email contains an FTP URL where the product can be downloaded. \n",
    "\n",
    "For this tutorial we will download the GACOS product into a *gacos_download* processing folder. As we are processing this tutorial remotely, we will be using commandline **wget** for the download of the products. \n",
    "```\n",
    "cd gacos_download\n",
    "wget GACOS_FILE.tar.gz\n",
    "```\n",
    "We will use the command line **tar** functionality to unzip the file\n",
    "```\n",
    "tar -xvf GACOS_FILE.tar.gz\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>GACOS NOTES:</b> \n",
    "<br>\n",
    "- The delays provided by GACOS are in meter units.\n",
    "<br>\n",
    "- Suffix *.ztd* refers to the zenith (vertical column) tropospheric delay, and *.dztd* refers to the differential *.ztd*. \n",
    "<br>\n",
    "- The GACOS ReadMe.pdf contains more information on the definition and references.\n",
    "</div>\n",
    "\n",
    "\n",
    "**In case you are having issue with the download of the product proceed below, if not, skip directly to Section 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### In case of unsuccessful download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In case you are unable to download the product, we have already downloaded it for this tutorial in the gacos folder. You can copy this folder content into the *gacos_download* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copy in the GACOS data \n",
    "cmd = \"cp -r \" + os.path.join(gacos_backup_dir,'*') + \" \" + os.path.join(gacos_dir,'.')\n",
    "os.system(cmd)\n",
    "!ls gacos_download/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ls gacos_download/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3. SAR Tropospheric phase delay (slant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this chapter we will convert the GACOS pseudo-range zenith tropospheric delays, into the projection reference as the geo-coded interferogram and project the zenith delay to the slant using the incidence angle information.\n",
    "$$\\Phi_{\\text{slant}}=\\frac{-4 \\pi}{\\lambda* cos(\\theta)}*d_{\\text{zenith}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.1 Creating ENVI header files¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "GACOS  supports both tiff and Envi file formats. The pre-staged data is assuming ENVI format, which requires an additional pre-processing step. When selecting tiff, skip this step.\n",
    "</div>\n",
    "\n",
    "We will be using GDAL to interpolate the GACOS products on the same grid as our geocoded interferogram. The Binary grid format is not directly compatible with GDAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!gdalinfo gacos_download/20171111.ztd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "This can be solved by making a new ENVI .hdr file. Below we include a function loadrsc which will open the GACOS .rsc file and load the relevant information. Another provided function will generate the .hdr file using a predefined template and the information extracted from the .rsc file. Execute the following cell to make these functions available for usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loadrsc(infile):\n",
    "    '''A function to load the content of .rsc file and pass it back as a dictionary'''\n",
    "    import numpy as np\n",
    "    with open(infile + '.rsc') as f:\n",
    "        text = f.read()\n",
    "    lines = [e.split() for e in text.split(\"\\n\") if e != \"\"]\n",
    "    headers = dict(lines)\n",
    "    # add the filename such it can be called when making envi header\n",
    "    headers['FILENAME'] = infile\n",
    "    # take the abs of the y-spacing as upper left corner is to be specified\n",
    "    headers['Y_STEP'] = str(np.abs(float(headers['Y_STEP'])))\n",
    "    return headers\n",
    "\n",
    "def writehdr(filename,headers):\n",
    "    '''A function that writes a .hdr file from a template and a dictionarydescribing the fields'''\n",
    "    print('Writing output HDR file...')\n",
    "    print(headers)\n",
    "    enviHDRFile = open(filename + '.hdr', 'w')\n",
    "    enviHDR = '''ENVI\n",
    "description = {{GACOS: {FILENAME} }}\n",
    "samples = {WIDTH}\n",
    "lines = {FILE_LENGTH}\n",
    "bands = 1\n",
    "header offset = 0\n",
    "file type = ENVI Standard\n",
    "data type = 4\n",
    "interleave = bsq\n",
    "sensor type = Unknown\n",
    "byte order = 0\n",
    "map info = {{Geographic Lat/Lon, 1, 1, {X_FIRST}, {Y_FIRST}, {X_STEP}, {Y_STEP}, WGS-84, units=Degrees}}\n",
    "coordinate system string = {{GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.017453292519943295]]}}'''.format(**headers)\n",
    "\n",
    "    enviHDRFile.write(enviHDR)\n",
    "    enviHDRFile.close()\n",
    "    print('Output HDR file =', filename)\n",
    "\n",
    "def GACOS_rsc2hdr(inputfile):\n",
    "    '''\n",
    "    Wrapper code which calls .rsc reader and .hdr writer functionality \n",
    "    '''\n",
    "\n",
    "    print('Generating hdr file for: ' + inputfile + '...')\n",
    "    # make sure the user does not give a header file as input\n",
    "    filename, file_extension = os.path.splitext(inputfile)\n",
    "    if file_extension == '.hdr' or file_extension == '.rsc':\n",
    "        raise Exception(\"Give path to the ENVI file not the .hdr or .rsc file\")\n",
    "    headers = loadrsc(inputfile)\n",
    "    writehdr(inputfile,headers)\n",
    "    print('hdr for ' + inputfile + ' generated')\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will generate the header files for all the SAR delays files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "GACOS_rsc2hdr('gacos_download/20171111.ztd')\n",
    "GACOS_rsc2hdr('gacos_download/20171117.ztd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us verify if the files are now GDAL compatible, and if the geo-reference information is correctly represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!gdalinfo gacos_download/20171117.ztd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1 Geo-coordinate mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the next step, we will interpolate GACOS data to the grid of the geo-coded interferogram. Below we include a function **file_transform** which will allow us to do this using GDAL. It takes three inputs, namely the unwrapped ISCE file, the GACOS APS file, and an output filename. \n",
    "\n",
    "Execute the following cell to make this function available for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def file_transform(unwfile,apsfile,apsfile_out):\n",
    "    '''\n",
    "    convert the aps file into the same geo frame as the unw file\n",
    "    Unwfile is an envi file and has a corresponding vrt file\n",
    "    aps file is gdal compatible\n",
    "    '''\n",
    "    import isceobj\n",
    "    from osgeo import gdal, gdalconst\n",
    "    #from gdal2isce_xml import gdalisce2XML\n",
    "\n",
    "    # convert all to absolute paths\n",
    "    apsfile = os.path.abspath(apsfile)\n",
    "    apsfile_out = os.path.abspath(apsfile_out)\n",
    "\n",
    "    # Source\n",
    "    src = gdal.Open(apsfile, gdalconst.GA_ReadOnly)\n",
    "    src_proj = src.GetProjection()\n",
    "    src_geotrans = src.GetGeoTransform()\n",
    "    print(\"Working on \" + apsfile )\n",
    "    # We want a section of source that matches this:\n",
    "    match_ds = gdal.Open(unwfile + '.vrt', gdalconst.GA_ReadOnly)\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    print(\"Getting target reference information\")\n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "    \n",
    "    # Output / destination\n",
    "    dst = gdal.GetDriverByName('envi').Create(apsfile_out, wide, high, 1, gdalconst.GDT_Float32)\n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection( match_proj)\n",
    "\n",
    "    # Do the work\n",
    "    gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "    print(\"Done\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # closing the images\n",
    "    dst = None\n",
    "    src = None\n",
    "\n",
    "    ## run gdal 2 isce on this file so we can use ISCE functionality latter on\n",
    "    #gdalisce2XML(apsfile_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will interpolate all the SAR delays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.chdir(processing_dir)\n",
    "file_transform('filt_topophase.unw.geo',os.path.join(gacos_dir,'20171117.ztd'),'20171117.ztd.geo')\n",
    "file_transform('filt_topophase.unw.geo',os.path.join(gacos_dir,'20171111.ztd'),'20171111.ztd.geo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "If using tiff format, then the following should be used.\n",
    "    \n",
    "- os.chdir(processing_dir)\n",
    "- file_transform('filt_topophase.unw.geo',os.path.join(gacos_dir,'20171117.ztd.tif'),'20171117.ztd.geo')\n",
    "- file_transform('filt_topophase.unw.geo',os.path.join(gacos_dir,'20171111.ztd.tif'),'20171111.ztd.geo')\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us visualize the zenith delays for both the reference and secondary acquisition. Typical tropospheric delays reach magnitudes up to 2.5 m. Are you expecting to see a lot of difference between both days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotdata2('20171111.ztd.geo','20171117.ztd.geo',1,title=['Secondary zenith delay [m]: 20171111','Reference zenith delay [m]: 20171117'],colormap='jet',datamin=1.7, datamax=2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.2 Converting zenith tropopsheric delay to slant phase delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we will project the zenith delay into the radar slant (radar look direction) by using a simple cosine mapping function of the incidence angle, and at the same time apply the scaling to convert from pseudo-range to phase \n",
    "$$\\Phi_{\\text{slant}}=\\frac{-4 \\pi}{\\lambda* cos(\\theta)}*d_{\\text{zenith}}$$\n",
    "The **zenith2slant** function included below takes the geocoded zenith APS file as well as the LOS file as inputs and outputs an ENVI geo-coded slant delay file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    " def zenith2slant(losfile,aps_zenith,aps_slant):\n",
    "    \n",
    "    # convert all to absolute paths\n",
    "    aps_zenith = os.path.abspath(aps_zenith)\n",
    "    aps_slant = os.path.abspath(aps_slant)\n",
    "    losfile = os.path.abspath(losfile)\n",
    "    \n",
    "    # loading the zenith APS file\n",
    "    ds = gdal.Open(aps_zenith, gdal.GA_ReadOnly)\n",
    "    zenith = ds.GetRasterBand(1).ReadAsArray()\n",
    "    proj = ds.GetProjection()\n",
    "    geotrans = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    \n",
    "    # loading the incidence angle file\n",
    "    ds = gdal.Open(losfile, gdal.GA_ReadOnly)\n",
    "    inc = ds.GetRasterBand(1).ReadAsArray()\n",
    "    ds = None\n",
    "    # convert the inc from deg to rad\n",
    "    inc = inc*np.pi/180\n",
    "    \n",
    "    # scaling factor to convert pseudo-range [m] increase to phase delay [rad]\n",
    "    scaling = -4*np.pi/5.6*100\n",
    "    \n",
    "    # projecting the zenith into the slant\n",
    "    slant = scaling*zenith/np.cos(inc)\n",
    "    \n",
    "    # making sure the no-date is propagated\n",
    "    slant[zenith==0]=0\n",
    "    slant[inc==0]=0\n",
    "        \n",
    "    \n",
    "    # writing out the file   \n",
    "    drv = gdal.GetDriverByName('envi').Create(aps_slant, slant.shape[1], slant.shape[0], 1,gdal.GDT_Float32)\n",
    "    drv.SetGeoTransform(geotrans)\n",
    "    drv.SetProjection(proj)\n",
    "    drv.GetRasterBand(1).WriteArray(slant)\n",
    "    drv = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will run this function for both SAR acquisitions and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zenith2slant('los.rdr.geo.vrt','20171117.ztd.geo','20171117.aps.geo')\n",
    "zenith2slant('los.rdr.geo.vrt','20171111.ztd.geo','20171111.aps.geo')\n",
    "plotdata2('20171111.aps.geo','20171117.aps.geo',1,title=['Secondary slant phase delay [rad]: 20171111','Reference slant phase delay [rad]: 20171117'],colormap='jet',datamin=-725, datamax=-525)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4. InSAR Tropospheric phase delay (slant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we have a tropospheric phase delay estimated for both SAR acquisitions, we can compute the differential delay. Note it is important to apply the same convention as you did when making the interferogram. Below we include the **differential_delay** function which takes a reference and secondary APS files as input as well as an output name.\n",
    "\n",
    "By investigating the orignal *topsApp.xml* file you can see that the reference was selected as 20171117 and the secondary as 20171111."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\\Delta \\Phi_{\\text{slant}}=\\Phi_{\\text{slant}}^{\\text{reference}}- \\Phi_{\\text{slant}}^{\\text{secondary}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def differential_delay(reference_aps,secondary_aps,outname):\n",
    "    \n",
    "    # convert all to absolute paths\n",
    "    reference_aps = os.path.abspath(reference_aps)\n",
    "    secondary_aps = os.path.abspath(secondary_aps)\n",
    "    outname = os.path.abspath(outname)\n",
    "    \n",
    "    # loading the reference APS file\n",
    "    ds = gdal.Open(reference_aps, gdal.GA_ReadOnly)\n",
    "    reference = ds.GetRasterBand(1).ReadAsArray()\n",
    "    proj = ds.GetProjection()\n",
    "    geotrans = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    \n",
    "    # loading the secondary APS file\n",
    "    ds = gdal.Open(secondary_aps, gdal.GA_ReadOnly)\n",
    "    secondary = ds.GetRasterBand(1).ReadAsArray()\n",
    "    ds = None\n",
    "    \n",
    "    \n",
    "    # computing the differential APS\n",
    "    diffAPS = reference-secondary\n",
    "    \n",
    "    # writing out the file \n",
    "    drv = gdal.GetDriverByName('envi').Create(outname, diffAPS.shape[1], diffAPS.shape[0], 1,gdal.GDT_Float32)\n",
    "    drv.SetGeoTransform(geotrans)\n",
    "    drv.SetProjection(proj)\n",
    "    drv.GetRasterBand(1).WriteArray(diffAPS)\n",
    "    drv = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Below we will execute the **differential_delay** function, and plot the results. From the results you can see that even though the SAR delays looked quite similar there is spatial variation of up to 14 rad. Keeping in mind that 6.28 rad is equivalent to 2.8 cm, we find about 6.2 cm of delay for our intergerogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "differential_delay('20171117.aps.geo','20171111.aps.geo','20171117_20171111.aps.geo')\n",
    "plotdata('20171117_20171111.aps.geo',1,title=\"Differential phase delay (20171117-20171111) [rad] \",colormap='jet',colorbar_orientation=\"vertical\",datamin=-6, datamax=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5. Applying InSAR Tropospheric correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As last step we will correct our original interferogram for the estimated tropospheric phase delay. Below we provide the function to do the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def IFG_correction(unw,aps,outname):\n",
    "    \n",
    "    # convert all to absolute paths\n",
    "    unw = os.path.abspath(unw)\n",
    "    aps = os.path.abspath(aps)\n",
    "    outname = os.path.abspath(outname)\n",
    "    \n",
    "    # loading the UNW file\n",
    "    ds = gdal.Open(unw, gdal.GA_ReadOnly)\n",
    "    unwdata_phase = ds.GetRasterBand(2).ReadAsArray()\n",
    "    unwdata_amplitude = ds.GetRasterBand(1).ReadAsArray()\n",
    "    proj = ds.GetProjection()\n",
    "    geotrans = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    \n",
    "    # loading the APS file\n",
    "    ds = gdal.Open(aps, gdal.GA_ReadOnly)\n",
    "    apsdata = ds.GetRasterBand(1).ReadAsArray()\n",
    "    ds = None\n",
    "    \n",
    "    # Correcting the IFG\n",
    "    unwdata_phase = unwdata_phase-apsdata\n",
    "    # making sure the no-date is propagated\n",
    "    unwdata_phase[unwdata_phase==0]=0\n",
    "    unwdata_phase[apsdata==0]=0 \n",
    "    \n",
    "    \n",
    "    # writing out the file \n",
    "    drv = gdal.GetDriverByName('envi').Create(outname, unwdata_phase.shape[1], unwdata_phase.shape[0], 2,gdal.GDT_Float32)\n",
    "    drv.SetGeoTransform(geotrans)\n",
    "    drv.SetProjection(proj)\n",
    "    drv.GetRasterBand(1).WriteArray(unwdata_amplitude)\n",
    "    drv.GetRasterBand(2).WriteArray(unwdata_phase)\n",
    "    drv = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using this function, we will now compute the correction and make a comparison plot before and after correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IFG_correction('filt_topophase.unw.geo.vrt','20171117_20171111.aps.geo','filt_topophase_aps.unw.geo')\n",
    "plotdata2('filt_topophase.unw.geo','filt_topophase_aps.unw.geo',2,title=[\"UNW before [rad]\",'UNW after APS correction [rad]'],colormap='jet',datamin=-50, datamax=50,plot_profile='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant references:\n",
    "**GACOS**:\n",
    "- Yu, C., N. T. Penna, and Z. Li (2017), Generation of real-time mode high-resolution water vapor fields from GPS observations, J. Geophys. Res. Atmos., 122, 2008–2025, doi:10.1002/2016JD025753\n",
    "- Yu, C., Z. Li, and N. T. Penna (2017), Interferometric synthetic aperture radar atmospheric correction using a GPS-based iterative tropospheric decomposition model, Remote Sens. Environ., doi:10.1016/j.rse.2017.10.038.\n",
    "\n",
    "**Comparison of Tropospheric correction methods**\n",
    "- D.P.S. Bekaert, R.J. Walters, T.J. Wright, A.J. Hooper, and D.J. Parker (2015) Statistical comparison of InSAR tropospheric correction techniques, Remote Sensing of Environment, doi:10.1016/j.rse.2015.08.035."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
