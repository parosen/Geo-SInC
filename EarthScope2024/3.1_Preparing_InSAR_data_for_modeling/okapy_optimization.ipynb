{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversions with okapy and SciPy\n",
    "\n",
    "A simple inversion making use of the Powell algorithm built into the scipy.optimize.minimize function, the Okada model in okapy and our downsampled data in 'okinv' format to try to obtain a best-fitting model of an earthquake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set it up! \n",
    "\n",
    "Let's start with some dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okapy import rect_shear_fault, los_penalty_fault\n",
    "from math import sin, cos, tan, radians, floor\n",
    "from matplotlib import cm, colors\n",
    "from scipy.optimize import minimize, Bounds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the data, model parameters and elastic constants\n",
    "\n",
    "Load in the downsampled interfrogram data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('./elazig_asc.okinv', delimiter=' ') # or wherever the file is on your system!\n",
    "data[:,0]*=1000  # convert x coord from km to m\n",
    "data[:,1]*=1000  # convert y coord from km to m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify some parameters for our models: starting guesses and uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each quantity, starting guess is the first value, sigma the second\n",
    "strike = [60, 10]        # in degrees\n",
    "dip = [90, 15]           # in degrees\n",
    "rake = [1, 20]           # in degrees\n",
    "slip = [2, 0.75]          # in m\n",
    "xs = [500000, 5000]        # x coord of center of updip fault projection, in m \n",
    "ys = [4240000, 5000]       # y coord of same, in m\n",
    "as_length = [35000, 5000]     # along-strike fault length, in m\n",
    "top_depth = [4000, 2000]      # depth of top edge of fault, in m\n",
    "bottom_depth = [12000, 5000]  # depth to bottom edge of fault\n",
    "\n",
    "fpstart = np.array([strike[0], dip[0], rake[0], slip[0], xs[0], ys[0], as_length[0], top_depth[0], bottom_depth[0]])\n",
    "fpsigma = np.array([strike[1], dip[1], rake[1], slip[1], xs[1], ys[1], as_length[1], top_depth[1], bottom_depth[1]])\n",
    "\n",
    "# let's calculate some 2-sigma bounds on these starting values:\n",
    "fplowb = fpstart-2*np.array([strike[1], dip[1], rake[1], slip[1], xs[1], ys[1], as_length[1], top_depth[1], bottom_depth[1]])\n",
    "fphighb = fpstart+2*np.array([strike[1], dip[1], rake[1], slip[1], xs[1], ys[1], as_length[1], top_depth[1], bottom_depth[1]])\n",
    "\n",
    "# find a random starting model (assume flat pdf between lower and upper bounds)\n",
    "fparams_restart = fpstart + np.multiply(((np.random.random_sample(9)*4)-2),fpsigma)\n",
    "\n",
    "# sanity check of depths (make sure bottom depth is greater than top depth)\n",
    "if fparams_restart[7] > fparams_restart[8]:\n",
    "    bottom = fparams_restart[7]\n",
    "    fparams_restart[7] = fparams_restart[8] \n",
    "    fparams_restart[8] = bottom\n",
    "    \n",
    "# and output the starting model    \n",
    "print(\"example starting fault parameters:\")\n",
    "print('  strike:',fparams_restart[0],'dip:',fparams_restart[1],'rake:',fparams_restart[2],'slip:',fparams_restart[3])\n",
    "print('  xs:',fparams_restart[4],'ys:',fparams_restart[5])\n",
    "print('  length:',fparams_restart[6],'top:',fparams_restart[7],'bottom:',fparams_restart[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define some elastic parameters, using some standard values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eparams = np.array([30e9, 30e9])  # 1st and 2nd Lame elastic parameters; try 30 GPa for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the penalty function for a random starting model\n",
    "\n",
    "We now have all the elements we need to calculate an initial penalty value, using the los_penalty_fault function in okapy. This function has the following syntax: \n",
    "\n",
    "<center>penalty=los_penalty_fault(fparams, eparams, data)</center>\n",
    "\n",
    "The output argument, 'penalty' is the total squared misfit of the model to the data, accounting for a zero-level shift.\n",
    "\n",
    "There are three input arguments, for which we have already seen examples. 'fparams' is a vector of fault parameters, of the type we have already seen (e.g. fstart, fparams_restart), 'eparams' contains elastic constants, and 'data' is a matrix of data point locations, values and line-of-sight parameters. (You may recognize that these are the same inputs that we used to compute our forward model displacements in the forward modeling notebook...)\n",
    "\n",
    "For example, we can evaluate the penalty function for our starting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_penalty = los_penalty_fault(fparams_restart, eparams, data)\n",
    "\n",
    "print('initial penalty:',init_penalty, 'm^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing fault parameters using the Powell algorithm in SciPy\n",
    "\n",
    "The <a href=\"https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize\">'optimize.minimize'</a> function in SciPy is a very flexible optimization package that can apply several different optimization algorithms to the problem of minimizing a specified nonlinear function. Here we want to find the parameter values that minimize our penalty function, 'los_penalty_fault'.\n",
    "\n",
    "We will make use of the <a href=\"https://en.wikipedia.org/wiki/Powell%27s_method\">Powell algorithm</a>, which is a 'direction set' minimization algorithm that, in our experience, works well for these sorts of problems. It allows us to specify bounds on the inversion parameters, which is particularly useful for limiting the range of models it will test. The Powell algorithm also requires a starting guess, for which we will use our random starting model ('fparams_restart'). \n",
    "\n",
    "Note that our 'los_penalty_fault' function has three input arguments &ndash; the fault parameters, the elastic parameters and the data. We only want the Powell algorithm to vary the first of these (which it does by default), but we need to pass all three to properly evaluate the penalty. scipy.optimize allows us to pass the additional arguments to the penalty function using the 'args' option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the results of this optimization run, by printing the contents of 'results':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the scipy.optimize way of setting bounds:\n",
    "fpbounds = Bounds(fplowb,fphighb)\n",
    "\n",
    "# and run the Powell algorithm minimizer! \n",
    "results = minimize(los_penalty_fault, fparams_restart, args=(eparams, data),  method='Powell', \n",
    "                   bounds=fpbounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these, 'direc' shows directions in parameter space that the algorithm took; 'fun' is the final, minimum value of the penalty function; 'nfev' is the number of penalty function evaluations (which might explain the delay in getting a result); 'nit' is the number of iterations (direction changes), and 'x' is the final set of fault parameters (that correspond to the minimum penalty, 'fun'). \n",
    "\n",
    "We can extract the values of interest here, and hopefully verify that the final penalty is smaller than the one we started with:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fparams_out = results.x\n",
    "output_penalty = results.fun\n",
    "\n",
    "print(\"final fault parameters:\")\n",
    "print('  strike:',fparams_out[0],' dip:',fparams_out[1],' rake:',fparams_out[2],' slip:',fparams_out[3])\n",
    "print('  xs:',fparams_out[4],' ys:',fparams_out[5])\n",
    "print('  length:',fparams_out[6],' top:',fparams_out[7],' bottom:',fparams_out[8])\n",
    "print('initial penalty:',init_penalty,'m^2  final penalty:',output_penalty,'m^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local vs global minima\n",
    "\n",
    "Technically, what our single run of the Powell algorithm has found is a 'local minimum' of the penalty function. For complicated functions, such as the penalty function of an Okada model fitted to InSAR data that contain noise (our situation!) it is usually the case that there are several, or perhaps many such minima. It's analous to finding the deepest point on the surface of the Moon, by always taking the steepest path downhill. Eventually, you will walk into a crater, and find your way to the bottom of it. But what if two craters over, there is a deeper one?\n",
    "\n",
    "The problem of finding a 'global minimum' of the penalty function, corresponding to the best-fitting of all possible models, is not straightforward or exact. Following the crater analogy, it can be very dependent on your starting location &ndash; sometimes you need to start away from smaller holes in order to walk into bigger ones! Which is why, when we set up this optimization problem, we randomized our starting guess of the answer. You also have to be careful to specify solution bounds large enough that the neighborhood of the best answer is covered. \n",
    "\n",
    "By comparing your answer with your classmates' answers, which originated from different random starting guesses, within a fairly conservative set of bounds,  you should be able to see if there are smaller misfits out there. Or alternatively, if you don't want to crowdsource the problem, you could loop through a large number (say 100) of optimization runs with randomised starting guesses (you will often see these described as 'Monte Carlo restarts'), and retain the best models and penalties from each, in order to find a global minimum solution. (We've put a code snippet that does that at the bottom of the notebook.) \n",
    "\n",
    "Paste the best answer you can find here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fparams=[]\n",
    "best_penalty="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is good practice to plot your results and residuals\n",
    "\n",
    "We can use the routines we developed in earlier notebooks to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the displacements\n",
    "model_los_disps = rect_shear_fault(best_fparams, eparams, data)\n",
    "\n",
    "# calculate the mean residual\n",
    "zero_shift = np.mean(data[:,2]-model_los_disps)\n",
    "\n",
    "# calculate the residual without nuisances...\n",
    "shifted_data = data[:,2]-zero_shift\n",
    "residual_los_disps = model_los_disps-shifted_data\n",
    "\n",
    "# color limits based on the shifted data\n",
    "cmin, cmax = shifted_data.min(), shifted_data.max()\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(18,8))\n",
    "axlist = [ax1,ax2,ax3]   # handles for your subplots\n",
    "\n",
    "# scatter with colormap mapping to z value\n",
    "scat=ax1.scatter(data[:,0],data[:,1],s=20,c=shifted_data, marker = 'o', cmap = cm.jet, vmin = cmin, vmax = cmax);\n",
    "ax1.set_xlabel(\"UTM x (m)\",fontsize=12)\n",
    "ax1.set_ylabel(\"UTM y (m)\",fontsize=12)\n",
    "ax1.title.set_text('data')\n",
    "ax1.grid(True,linestyle='-',color='0.75')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# scatter with colormap mapping to z value\n",
    "scat=ax2.scatter(data[:,0],data[:,1],s=20,c=model_los_disps, marker = 'o', cmap = cm.jet, vmin = cmin, vmax = cmax);\n",
    "ax2.set_xlabel(\"UTM x (m)\",fontsize=12)\n",
    "ax2.title.set_text('inverse model')\n",
    "ax2.grid(True,linestyle='-',color='0.75')\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "# scatter with colormap mapping to z value\n",
    "scat=ax3.scatter(data[:,0],data[:,1],s=20,c=residual_los_disps, marker = 'o', cmap = cm.jet, vmin = cmin, vmax = cmax);\n",
    "ax3.set_xlabel(\"UTM x (m)\",fontsize=12)\n",
    "ax3.title.set_text('residual')\n",
    "ax3.grid(True,linestyle='-',color='0.75')\n",
    "ax3.set_aspect('equal')\n",
    "\n",
    "clb=fig.colorbar(scat,ax=axlist)\n",
    "clb.ax.set_title('LOS disp (m)')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: looping to find the global minimum\n",
    "\n",
    "If you don't have over 100 classmates to crowdsource the problem, the next best thing is to loop through a lot of optimizations from different starting models yourself, and select the model with the lowest penalty.\n",
    "\n",
    "Shown here is one strategy for doing this. We make a variable for the best penalty function ('bestfun'), and initialize it with an extremely large number (if your penalties are bigger than this, your starting model has some problems!) Next, we loop through 100 model runs, and each time, select a new random starting model, run the optimization, compare the misfit to our best penalty function, and if it is better, we update bestfun with the new best penalty function, and also save the best fault parameters in an array ('bestparams'). At the end, bestparams should contain the best fault parameters that the optimization could find, and bestfun should have the best penalty. \n",
    "\n",
    "Obviously, this takes a lot longer than running the optimization once, so maybe you could try it in your spare time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfun=1e30\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "# find a random starting model (assume flat pdf between lower and upper bounds)\n",
    "    fparams_restart = fpstart + np.multiply(((np.random.random_sample(9)*4)-2),fpsigma)\n",
    "\n",
    "# sanity check of depths (make sure bottom depth is greater than top depth)\n",
    "    if fparams_restart[7] > fparams_restart[8]:\n",
    "        bottom = fparams_restart[7]\n",
    "        fparams_restart[7] = fparams_restart[8] \n",
    "        fparams_restart[8] = bottom\n",
    "\n",
    "# the scipy.optimize way of setting bounds:\n",
    "    fpbounds = Bounds(fplowb,fphighb)\n",
    "\n",
    "# and run the Powell algorithm minimizer! \n",
    "    results = minimize(los_penalty_fault, fparams_restart, args=(eparams, data),  method='Powell', \n",
    "                   bounds=fpbounds)\n",
    "\n",
    "    if results.fun<bestfun:\n",
    "        bestfun=results.fun\n",
    "        bestparams = results.x\n",
    "        \n",
    "    print(\"run {0:d}, penalty: {1:f}, best penalty: {2:f}\".format(i,results.fun,bestfun)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthscope_insar [conda env:.local-earthscope_insar]",
   "language": "python",
   "name": "conda-env-.local-earthscope_insar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
