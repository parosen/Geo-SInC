{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4df7c6",
   "metadata": {},
   "source": [
    "# Generating SLC stacks with topsStack\n",
    "\n",
    "**Authors**: Bryan Riel\n",
    "\n",
    "In this notebook, we will briefly demonstrate how to use `topsStack` to generate a stack of co-registered Sentinel-1 SLCs. The processing setup is identical to normal `topsApp.py` processing in that we download the appropriate SLC data, prepare a DEM for our study area, and download the necessary orbit and aux files from ASF/ESA (see previous tutorials on processing in TOPS mode with `topsApp.py`). More info on preparing for stacks can be found [here](https://github.com/parosen/Geo-SInC/tree/main/EarthScope2023/5.4_Intro_to_preparing_data_for_stack_processing).\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"4\"> <b> <font color='rgba(200,0,0,0.2)'> DISCLAIMER:  </font> </b> </font>\n",
    "\n",
    "The following notebook has been run offline and is for demonstration purposes only. In order to run this notebook for your own data, you will need to download SLCs into an `asf` directory, place all orbits in an `orbits` directory, and all other auxiliary files in the `aux` directory. </i></b>\n",
    "</div>\n",
    "\n",
    "## Study area and setup\n",
    "\n",
    "In this tutorial, our study area is Pine Island Glacier (PIG) in West Antartica. PIG is a fast-flowing ice stream and is responsible for about 25% of the mass loss from Antarctica for the past few decades. Here, we will use Sentinel-1 A/B IW SLCs for path 65, frame 906 (ascending) for two dates: 2020-01-12 and 2020-01-18. Moreover, we will only use one swath (Swath 2), which contains most of the fast-flowing regions of PIG (see image in main dense offsets notebook).\n",
    "\n",
    "For the digital elevation model (DEM), we will use the Reference Elevation Model of Antarctica (REMA) 100 meter mosaic, which can be accessed here (https://www.pgc.umn.edu/data/rema/). We warp the REMA data from Polar Stereographic South to WGS84 and apply a geoid correction in order to use for ISCE processing. \n",
    "\n",
    "Let's first import necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f789afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import datetime\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "import scipy.ndimage as ndimage\n",
    "import isce\n",
    "\n",
    "# Set environment variables for ISCE\n",
    "isce_path = os.path.join(isce.__path__[0].strip(), 'applications')\n",
    "os.environ['PATH'] = f\"{isce_path}:{os.environ['PATH']}\"\n",
    "\n",
    "# setup path for topsStack\n",
    "# $ISCE_STACK is set by conda\n",
    "sys.path.insert(0, os.environ['ISCE_STACK'])\n",
    "stack_path = os.path.join(os.environ['ISCE_STACK'], 'topsStack')\n",
    "os.environ['PATH'] = f\"{stack_path}:{os.environ['PATH']}\"\n",
    "os.environ['PYTHONPATH'] = f\"{os.environ['ISCE_STACK']}:{os.environ['PYTHONPATH']}\"\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "plt.rc('font', size=13)\n",
    "parent_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d3050",
   "metadata": {},
   "source": [
    "Let's explore our top-level directory structure. Here, the S1A/B SLC zip files have been downloaded into the `asf` directory, and the orbit and auxiliary data have been downloaded into the `orbits` and `aux` directories, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29432c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls asf\n",
    "print('')\n",
    "!ls orbits | tail\n",
    "print('')\n",
    "!ls aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce288983",
   "metadata": {},
   "source": [
    "### Running stackSentinel.py\n",
    "\n",
    "We use `stackSentinel.py` to generate all configuration and run files required to be executed for a stack of Sentinel-1 TOPS data. Let's first make sure we can find it in our path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dfdd7a-78ea-4d66-80e7-9436a5be04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which stackSentinel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2eb02-ad06-46d1-a070-39878a226bfe",
   "metadata": {},
   "source": [
    "We now point `stackSentinel.py` to our input data and relevant processing options:\n",
    "- `-W offset`: prepare files for generating dense offsets for various date pairs\n",
    "- `-c 2`: generate a max of 2 offset pairs between each date and subsequent date\n",
    "- `--swath_num '2'`: process swath 2\n",
    "- `-b': specify the bounding box\n",
    "- `-p hh`: specify HH polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88a2ef-9f02-4a75-9b07-7b048f26a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "(stackSentinel.py \\\n",
    "    -s asf \\\n",
    "    -o orbits \\\n",
    "     -a aux \\\n",
    "    -d pig_rema_100m_filled_wgs84.dem \\\n",
    "    -W offset \\\n",
    "    -c 2 \\\n",
    "    --swath_num '2' \\\n",
    "    -b '-75.6 -74.4 -104 -96' \\\n",
    "    -p hh \\\n",
    "    --num_proc 4 \\\n",
    "    --num_proc4topo 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a237c2b-0cad-46d6-8a77-d7d5666b50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure run files are executable\n",
    "!chmod a+x run_files/run_*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcb6c3-dc62-4460-b3a7-8e7d93544bea",
   "metadata": {},
   "source": [
    "### Stack processing steps\n",
    "\n",
    "We'll now go through each step of the processing by calling the run files one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e6f3e-047a-44a2-a20a-96ec74fb416b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run unpack and 'topo' step: this maps the DEM into the reference image geometry at burst overlaps.\n",
    "# This data is used for the co-registration of secondary images into the reference geometry\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "subprocess.run('./run_files/run_01_unpack_topo_reference', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e78673-c303-4a40-84e3-2f8ba3a491d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This unpacks all of the secondary SLC metadata\n",
    "subprocess.run('./run_files/run_02_unpack_secondary_slc', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591a0aa-af2f-4413-b547-b4d103952631",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the average baseline between the secondary and reference orbits\n",
    "subprocess.run('./run_files/run_03_average_baseline', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593aecdd-e07a-4389-a763-2db9d5059e05",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract SLC data over burst overlaps\n",
    "subprocess.run('./run_files/run_04_extract_burst_overlaps', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490fc7e-47cf-4b95-bcee-bff11ee56115",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute mapping from DEM (geographic) coordinates to radar burst coordinates for each secondary SLC\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "subprocess.run('./run_files/run_05_overlap_geo2rdr', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5116041-3012-4929-869c-633cc85d34e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample secondary bursts to reference geometry\n",
    "subprocess.run('./run_files/run_06_overlap_resample', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0de233-46a8-4f33-804c-482615bcf5ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute residual offsets between reference and secondary bursts over the overlaps\n",
    "subprocess.run('./run_files/run_07_pairs_misreg', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b6629-08a3-4f5a-8f1b-671961cd1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute time series of offsets for temporal consistency\n",
    "subprocess.run('./run_files/run_08_timeseries_misreg', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f431960-319a-4e36-8a19-978926d97578",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute mapping from DEM to radar coordinates for the full bursts for the secondary SLCs\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "subprocess.run('./run_files/run_09_fullBurst_geo2rdr', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f452aba-7a24-4537-a107-2ce86ec04e1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample secondary SLC bursts to reference\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "subprocess.run('./run_files/run_10_fullBurst_resample', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0be156-995e-4925-89c5-f3bf71c86443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the valid bursts (bursts that exist over all images)\n",
    "subprocess.run('./run_files/run_11_extract_stack_valid_region', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f6820-098f-4c1e-aaf3-79fa89df188a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute fully merged SLC images\n",
    "# This is the last step before dense offsets\n",
    "subprocess.run('./run_files/run_12_merge_reference_secondary_slc', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ce690-8491-4006-adea-8322031313fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l merged/SLC/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbaa1d-c32b-4479-8794-eb103834a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l merged/geom_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503b18f",
   "metadata": {},
   "source": [
    "We now have all the files necessary to generate dense offsets. Unlike `topsApp.py`, the `run_13_dense_offsets` step only generates the offsets in radar coordinates and does not perform any filtering or geocoding. Please see the main dense offsets notebook for a complete processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2f47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthscope_insar [conda env:.local-earthscope_insar]",
   "language": "python",
   "name": "conda-env-.local-earthscope_insar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
